{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzqfICPhuaug"
   },
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvx2xhxM54yG",
    "outputId": "e0080b98-b54a-461f-dcef-b6513455026e"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/baoguangsheng/fast-detect-gpt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aX6XEax_5-H9",
    "outputId": "8844b710-92ae-4124-8564-5d5d4e9550a5"
   },
   "outputs": [],
   "source": [
    "%cd fast-detect-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJi2xJkx723e",
    "outputId": "a6e28654-f17a-46b8-c77b-2c3222b38a51"
   },
   "outputs": [],
   "source": [
    "!pip install torch numpy transformers datasets matplotlib tqdm openai nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEZuFEWS_78w",
    "outputId": "baf1ce3d-8a52-4234-df4c-1021506d36b0"
   },
   "outputs": [],
   "source": [
    "%%writefile scripts/local_infer.py\n",
    "# Copyright (c) Guangsheng Bao.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import json\n",
    "from model import load_tokenizer, load_model\n",
    "from fast_detect_gpt import get_sampling_discrepancy_analytic\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Considering balanced classification that p(D0) equals to p(D1), we have\n",
    "# p(D1|x) = p(x|D1) / (p(x|D1) + p(x|D0))\n",
    "def compute_prob_norm(x, mu0, sigma0, mu1, sigma1):\n",
    "    pdf_value0 = norm.pdf(x, loc=mu0, scale=sigma0)\n",
    "    pdf_value1 = norm.pdf(x, loc=mu1, scale=sigma1)\n",
    "    prob = pdf_value1 / (pdf_value0 + pdf_value1)\n",
    "    return prob\n",
    "\n",
    "class FastDetectGPT:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.criterion_fn = get_sampling_discrepancy_analytic\n",
    "        self.scoring_tokenizer = load_tokenizer(args.scoring_model_name, args.cache_dir)\n",
    "        self.scoring_model = load_model(args.scoring_model_name, args.device, args.cache_dir)\n",
    "        self.scoring_model.eval()\n",
    "        if args.sampling_model_name != args.scoring_model_name:\n",
    "            self.sampling_tokenizer = load_tokenizer(args.sampling_model_name, args.cache_dir)\n",
    "            self.sampling_model = load_model(args.sampling_model_name, args.device, args.cache_dir)\n",
    "            self.sampling_model.eval()\n",
    "\n",
    "        distrib_params = {\n",
    "            'gpt-j-6B_gpt-neo-2.7B': {'mu0': 0.2713, 'sigma0': 0.9366, 'mu1': 2.2334, 'sigma1': 1.8731},\n",
    "            'gpt-neo-2.7B_gpt-neo-2.7B': {'mu0': -0.2489, 'sigma0': 0.9968, 'mu1': 1.8983, 'sigma1': 1.9935},\n",
    "            'falcon-7b_falcon-7b-instruct': {'mu0': -0.0707, 'sigma0': 0.9520, 'mu1': 2.9306, 'sigma1': 1.9039},\n",
    "        }\n",
    "        key = f'{args.sampling_model_name}_{args.scoring_model_name}'\n",
    "\n",
    "        # Fallback for KeyError\n",
    "        if key not in distrib_params:\n",
    "            print(f\"Warning: Key '{key}' not in distrib_params. Using 'gpt-neo-2.7B_gpt-neo-2.7B' as fallback.\")\n",
    "            key = 'gpt-neo-2.7B_gpt-neo-2.7B'\n",
    "\n",
    "        self.classifier = distrib_params[key]\n",
    "\n",
    "    # compute conditional probability curvature\n",
    "    def compute_crit(self, text):\n",
    "        tokenized = self.scoring_tokenizer(text, truncation=True, return_tensors=\"pt\", padding=True, return_token_type_ids=False).to(self.args.device)\n",
    "        labels = tokenized.input_ids[:, 1:]\n",
    "        if labels.size(1) == 0: # Handle empty or single-token text\n",
    "            return float('nan'), 0\n",
    "        with torch.no_grad():\n",
    "            logits_score = self.scoring_model(**tokenized).logits[:, :-1]\n",
    "            if self.args.sampling_model_name == self.args.scoring_model_name:\n",
    "                logits_ref = logits_score\n",
    "            else:\n",
    "                tokenized = self.sampling_tokenizer(text, truncation=True, return_tensors=\"pt\", padding=True, return_token_type_ids=False).to(self.args.device)\n",
    "                assert torch.all(tokenized.input_ids[:, 1:] == labels), \"Tokenizer is mismatch.\"\n",
    "                logits_ref = self.sampling_model(**tokenized).logits[:, :-1]\n",
    "            crit = self.criterion_fn(logits_ref, logits_score, labels)\n",
    "        return crit, labels.size(1)\n",
    "\n",
    "    # compute probability\n",
    "    def compute_prob(self, text):\n",
    "        crit, ntoken = self.compute_crit(text)\n",
    "        if np.isnan(crit):\n",
    "            return float('nan'), crit, ntoken\n",
    "        mu0 = self.classifier['mu0']\n",
    "        sigma0 = self.classifier['sigma0']\n",
    "        mu1 = self.classifier['mu1']\n",
    "        sigma1 = self.classifier['sigma1']\n",
    "        prob = compute_prob_norm(crit, mu0, sigma0, mu1, sigma1)\n",
    "        return prob, crit, ntoken\n",
    "\n",
    "# --- NEW FLEXIBLE MAIN BLOCK ---\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # --- Text argument is now OPTIONAL ---\n",
    "    parser.add_argument('--text', type=str, default=None, help='(Optional) Text to be analyzed.')\n",
    "    parser.add_argument('--sampling_model_name', type=str, default=\"gpt-neo-2.7B\")\n",
    "    parser.add_argument('--scoring_model_name', type=str, default=\"gpt-neo-2.7B\")\n",
    "    parser.add_argument('--device', type=str, default=\"cuda\")\n",
    "    parser.add_argument('--cache_dir', type=str, default=\"../cache\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --- EDIT THIS VARIABLE TO TEST YOUR TEXT ---\n",
    "\n",
    "    default_text_to_analyze = \"\"\"\n",
    "    i am human\n",
    "\"\"\"\n",
    "\n",
    "    # Check if --text argument was provided\n",
    "    if args.text is not None:\n",
    "      text_to_analyze = args.text\n",
    "      print(\"Using text provided from command line.\")\n",
    "    else:\n",
    "      text_to_analyze = default_text_to_analyze\n",
    "      print(\"No --text argument found. Using default text from script.\")\n",
    "\n",
    "    # 1. Initialize the detector\n",
    "    print(\"Initializing detector...\")\n",
    "    detector = FastDetectGPT(args)\n",
    "    print(\"Detector initialized.\")\n",
    "\n",
    "    # 2. Estimate the probability\n",
    "    print(f\"\\nAnalyzing text: '{text_to_analyze.strip()[:100]}...'\")\n",
    "    prob, crit, ntokens = detector.compute_prob(text_to_analyze)\n",
    "\n",
    "    # 3. Print the result\n",
    "    print(f'\\n--- Result ---')\n",
    "    if np.isnan(crit):\n",
    "        print(f'Could not analyze text. It might be too short or invalid.')\n",
    "    else:\n",
    "        print(f'Fast-DetectGPT criterion is {crit:.4f}')\n",
    "        print(f'Probability of being machine-generated: {prob * 100:.0f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2X9eIJS-IwS",
    "outputId": "89e6b092-02f2-4bfc-a283-f128a0be86e9"
   },
   "outputs": [],
   "source": [
    "!python scripts/local_infer.py \\\n",
    "    --scoring_model_name gpt-neo-2.7B \\\n",
    "    --sampling_model_name gpt-neo-2.7B \\\n",
    "    --text \"This second script is not DetectGPT and not the original Fast-DetectGPT paper method either — but it is a custom simplified Fast-DetectGPT-style heuristic, built on top of the analytic discrepancy function from your earlier code.\" \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mC1dWDGst0Y9"
   },
   "source": [
    "#Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Om1_QRh6VU7"
   },
   "outputs": [],
   "source": [
    "!mkdir -p baseline/exp_gpt3to4/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qikl5id99Uwn"
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# The original code contains some error - run the fixed version in the next cell\n",
    "##########################################################################################\n",
    "# # Run Fast-DetectGPT with GPT-Neo-2.7B (fits in Colab)\n",
    "# # Using black-box setting: sampling and scoring with surrogate models\n",
    "\n",
    "# dataset = \"xsum\"\n",
    "# source_model = \"gpt-3.5-turbo\"  # The model that generated the text\n",
    "# sampling_model = \"gpt-neo-2.7B\"  # Surrogate model for sampling\n",
    "# scoring_model = \"gpt-neo-2.7B\"   # Surrogate model for scoring\n",
    "\n",
    "# !python scripts/fast_detect_gpt.py \\\n",
    "#     --sampling_model_name {sampling_model} \\\n",
    "#     --scoring_model_name {scoring_model} \\\n",
    "#     --dataset {dataset} \\\n",
    "#     --dataset_file exp_gpt3to4/data/{dataset}_{source_model} \\\n",
    "#     --output_file exp_gpt3to4/results/{dataset}_{source_model}.{sampling_model}_{scoring_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EyhZdD19tUX",
    "outputId": "47c1593d-8ad6-4713-9b34-c9e3559d10cd"
   },
   "outputs": [],
   "source": [
    "# Quick Fix for Tokenizer Loading Issue\n",
    "import re\n",
    "import os\n",
    "\n",
    "def fix_tokenizer_calls():\n",
    "    \"\"\"Fix the load_tokenizer function calls\"\"\"\n",
    "\n",
    "    files_to_fix = [\n",
    "        'scripts/fast_detect_gpt.py',\n",
    "        'scripts/baselines.py',\n",
    "        'scripts/detect_gpt.py',\n",
    "        'scripts/detect_llm.py',\n",
    "    ]\n",
    "\n",
    "    for filepath in files_to_fix:\n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        old_pattern = r'load_tokenizer\\(([^,]+),\\s*args\\.dataset,\\s*([^)]+)\\)'\n",
    "        if not re.search(old_pattern, content):\n",
    "            continue\n",
    "\n",
    "        # Create backup\n",
    "        with open(filepath + '.backup', 'w') as f:\n",
    "            f.write(content)\n",
    "\n",
    "        # Apply fix\n",
    "        fixed_content = re.sub(\n",
    "            r'load_tokenizer\\(([^,]+),\\s*args\\.dataset,\\s*([^)]+)\\)',\n",
    "            r'load_tokenizer(\\1, \\2)',\n",
    "            content\n",
    "        )\n",
    "\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(fixed_content)\n",
    "\n",
    "        print(f\"✓ Fixed: {filepath}\")\n",
    "\n",
    "    print(\"\\n✓ Fix applied!\")\n",
    "\n",
    "fix_tokenizer_calls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPAJUBXF-BQb",
    "outputId": "e27e2767-139b-4404-a563-fe1b95533a07"
   },
   "outputs": [],
   "source": [
    "dataset = \"xsum\"\n",
    "source_model = \"gpt-3.5-turbo\"  # The model that generated the text\n",
    "sampling_model = \"gpt-neo-2.7B\"  # Surrogate model for sampling\n",
    "scoring_model = \"gpt-neo-2.7B\"   # Surrogate model for scoring\n",
    "\n",
    "!python scripts/fast_detect_gpt.py \\\n",
    "    --sampling_model_name {sampling_model} \\\n",
    "    --scoring_model_name {scoring_model} \\\n",
    "    --dataset {dataset} \\\n",
    "    --dataset_file exp_gpt3to4/data/{dataset}_{source_model} \\\n",
    "    --output_file baseline/exp_gpt3to4/results/{dataset}_{source_model}.{sampling_model}_{scoring_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE8H5ib12dld"
   },
   "source": [
    "## Performance summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZO28J3OCFhx"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def summarize_performance(json_file_path):\n",
    "    \"\"\"\n",
    "    Loads a JSON experiment file from fast-detect-gpt, calculates performance\n",
    "    statistics, and prints a formatted summary.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): The file path to the experiment's JSON output file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(json_file_path):\n",
    "        print(f\"Error: The file '{json_file_path}' was not found.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Open and load the JSON data\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # --- Extract Metadata ---\n",
    "        test_name = data.get('name', 'N/A')\n",
    "        n_samples = data.get('info', {}).get('n_samples', 'N/A')\n",
    "\n",
    "        # --- Extract Final Metrics ---\n",
    "        roc_auc = data.get('metrics', {}).get('roc_auc', 'N/A')\n",
    "        pr_auc = data.get('pr_metrics', {}).get('pr_auc', 'N/A')\n",
    "\n",
    "        # --- Extract and Calculate Prediction Statistics ---\n",
    "        predictions = data.get('predictions', {})\n",
    "        real_scores = predictions.get('real', [])\n",
    "        sampled_scores = predictions.get('samples', [])\n",
    "\n",
    "        # Calculate mean and std dev for human (\"real\") scores\n",
    "        if real_scores:\n",
    "            real_mean = np.mean(real_scores)\n",
    "            real_std = np.std(real_scores)\n",
    "        else:\n",
    "            real_mean = 'N/A'\n",
    "            real_std = 'N/A'\n",
    "\n",
    "        # Calculate mean and std dev for machine (\"sampled\") scores\n",
    "        if sampled_scores:\n",
    "            sampled_mean = np.mean(sampled_scores)\n",
    "            sampled_std = np.std(sampled_scores)\n",
    "        else:\n",
    "            sampled_mean = 'N/A'\n",
    "            sampled_std = 'N/A'\n",
    "\n",
    "        # --- Print the Summary Report ---\n",
    "        print(f\"--- Performance Summary for: {os.path.basename(json_file_path)} ---\")\n",
    "        print(f\"Test Name: {test_name}\")\n",
    "        print(f\"Number of Samples: {n_samples}\")\n",
    "        print(\"\\n--- Prediction Scores (Criterion) ---\")\n",
    "\n",
    "        # Print real scores statistics\n",
    "        if isinstance(real_mean, float):\n",
    "            print(f\"Human (Real) Scores Mean: {real_mean:.4f}\")\n",
    "            print(f\"Human (Real) Scores Std Dev: {real_std:.4f}\")\n",
    "        else:\n",
    "            print(\"Human (Real) Scores Mean: N/A\")\n",
    "            print(\"Human (Real) Scores Std Dev: N/A\")\n",
    "\n",
    "        # Print sampled scores statistics\n",
    "        if isinstance(sampled_mean, float):\n",
    "            print(f\"Machine (Sampled) Scores Mean: {sampled_mean:.4f}\")\n",
    "            print(f\"Machine (Sampled) Scores Std Dev: {sampled_std:.4f}\")\n",
    "        else:\n",
    "            print(\"Machine (Sampled) Scores Mean: N/A\")\n",
    "            print(\"Machine (Sampled) Scores Std Dev: N/A\")\n",
    "\n",
    "        print(\"\\n--- Key Metrics ---\")\n",
    "\n",
    "        # Print final metrics\n",
    "        if isinstance(roc_auc, float):\n",
    "            print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        else:\n",
    "            print(\"ROC AUC: N/A\")\n",
    "\n",
    "        if isinstance(pr_auc, float):\n",
    "            print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "        else:\n",
    "            print(\"PR AUC: N/A\")\n",
    "\n",
    "        print(\"-------------------------------------------------\" + \"-\" * len(os.path.basename(json_file_path)))\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from the file '{json_file_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rl4W8v_EFWrx",
    "outputId": "98c7857e-92f6-4243-878f-d49c763a286e"
   },
   "outputs": [],
   "source": [
    "file_path = './baseline/exp_gpt3to4/results/xsum_gpt-3.5-turbo.gpt-neo-2.7B_gpt-neo-2.7B.sampling_discrepancy.json'\n",
    "\n",
    "summarize_performance(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af2lVl_d0FLe"
   },
   "source": [
    "#All Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7WRdqBXtvm9"
   },
   "source": [
    "### Synonym Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCvBk6ZR0Gcg",
    "outputId": "b1d1944c-86c3-4935-b173-3623dab89ed7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Download required NLTK data (updated for newer NLTK versions)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')  # Added for newer NLTK\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')  # Added for newer NLTK\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Convert Penn Treebank POS to WordNet POS\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def get_synonyms(word, pos):\n",
    "    \"\"\"Get WordNet synonyms for a word\"\"\"\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word, pos=pos):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace('_', ' ')\n",
    "            if synonym.lower() != word.lower():\n",
    "                synonyms.add(synonym)\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_attack(text, replacement_rate=0.1):\n",
    "    \"\"\"Replace 10% of tokens with synonyms\"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Target content words (nouns, verbs, adjectives)\n",
    "    content_word_indices = [\n",
    "        i for i, (word, pos) in enumerate(pos_tags)\n",
    "        if pos.startswith(('NN', 'VB', 'JJ')) and word.isalpha()\n",
    "    ]\n",
    "\n",
    "    # Calculate exact number to replace based on total tokens\n",
    "    num_to_replace = int(len(tokens) * replacement_rate)\n",
    "\n",
    "    if not content_word_indices:\n",
    "        return text, 0\n",
    "\n",
    "    # Select random content words to replace\n",
    "    indices_to_replace = random.sample(\n",
    "        content_word_indices,\n",
    "        min(num_to_replace, len(content_word_indices))\n",
    "    )\n",
    "\n",
    "    modified_tokens = tokens.copy()\n",
    "    replacements_made = 0\n",
    "\n",
    "    for idx in indices_to_replace:\n",
    "        word, pos = pos_tags[idx]\n",
    "        wn_pos = get_wordnet_pos(pos)\n",
    "        synonyms = get_synonyms(word, wn_pos)\n",
    "\n",
    "        if synonyms:\n",
    "            modified_tokens[idx] = random.choice(synonyms)\n",
    "            replacements_made += 1\n",
    "\n",
    "    # Reconstruct text (simple join - may need refinement for punctuation)\n",
    "    result = ' '.join(modified_tokens)\n",
    "    # Fix common spacing issues\n",
    "    result = result.replace(' .', '.').replace(' ,', ',').replace(' !', '!').replace(' ?', '?')\n",
    "\n",
    "    return result, replacements_made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YEGI8-c3ZoY"
   },
   "source": [
    "## Strategic Perturbation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "We5nZT9k3h5z"
   },
   "outputs": [],
   "source": [
    "def strategic_perturbation_attack(text, replacement_rate=0.1):\n",
    "    \"\"\"\n",
    "    Replace common function words and determiners\n",
    "    These often don't change meaning much but affect probability\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Substitution dictionary\n",
    "    substitutions = {\n",
    "        'the': ['a', 'this', 'that'],\n",
    "        'a': ['the', 'one'],\n",
    "        'an': ['a', 'the'],\n",
    "        'is': ['was', 'seems', 'appears'],\n",
    "        'are': ['were', 'seem'],\n",
    "        'was': ['is', 'seemed'],\n",
    "        'were': ['are', 'seemed'],\n",
    "        'very': ['quite', 'really', 'extremely'],\n",
    "        'said': ['stated', 'mentioned', 'noted'],\n",
    "        'also': ['additionally', 'furthermore', 'moreover'],\n",
    "        'however': ['but', 'nevertheless', 'yet'],\n",
    "        'therefore': ['thus', 'hence', 'consequently'],\n",
    "    }\n",
    "\n",
    "    num_to_replace = int(len(tokens) * replacement_rate)\n",
    "    modified_tokens = tokens.copy()\n",
    "    replacements = 0\n",
    "\n",
    "    # Randomly shuffle indices to replace\n",
    "    replaceable_indices = [\n",
    "        i for i, token in enumerate(tokens)\n",
    "        if token.lower() in substitutions\n",
    "    ]\n",
    "    random.shuffle(replaceable_indices)\n",
    "\n",
    "    for idx in replaceable_indices[:num_to_replace]:\n",
    "        token = tokens[idx]\n",
    "        token_lower = token.lower()\n",
    "\n",
    "        if token_lower in substitutions:\n",
    "            replacement = random.choice(substitutions[token_lower])\n",
    "            # Preserve capitalization\n",
    "            if token[0].isupper():\n",
    "                replacement = replacement.capitalize()\n",
    "            modified_tokens[idx] = replacement\n",
    "            replacements += 1\n",
    "\n",
    "    result = ' '.join(modified_tokens)\n",
    "    result = result.replace(' .', '.').replace(' ,', ',').replace(' !', '!').replace(' ?', '?')\n",
    "\n",
    "    return result, replacements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcmstEqawMCe"
   },
   "source": [
    "## Paraphrase Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144,
     "referenced_widgets": [
      "f74beb2576ce45eca8c30dd18550d388",
      "c93cd9ff8c0241cb91b50211eb334247",
      "c9e58773e2ae4051b7ce1a9edb01572a",
      "4ef3acbf470f4da6af863a595038df0b",
      "4751bcf3494f42b1a9567a1f0a1f9493",
      "ada0bd624c514251835a0dd842b883fb",
      "6fbcaf69b7964e9f85fb30b7a06d4cfe",
      "ed7338d0bdfe4f3687983e226189d155",
      "abf30b3ca3ef476588c049397b89b185",
      "98ac2fdc093742f092da7ff2d952db45",
      "e3c6f2904728412f97a3f50ea8260f68",
      "da91c5bd05ea45a7ae14e7781979d194",
      "4d2e2a3bb9964a6ba974dddc33e879dc",
      "6d73d61d968940fcbb8e39fbd620af74",
      "60059e88b6424ca189519107166005aa",
      "582b2606d80b43ca97cbd998f9add1fb",
      "3d5c43d37c0c4c64bbaf1c5b7ea45e48",
      "462852038c45410aa12635394e5ad057",
      "ce8daf812e1f4b7a87f6f37961dd7b6d",
      "1db0b241bb5b4cdf89fbde0df020631e"
     ]
    },
    "id": "JRwokolg8f9I",
    "outputId": "e1b6cd26-bf0a-45d0-f295-48f49db9a7e9"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b85MyQUoPaHx"
   },
   "source": [
    "#### Hugging Face access issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVdDLDV9PeIy"
   },
   "source": [
    "If you submitted a model access application the first time, the typical approval time is around 10-30 minutes. Please wait for the approval of using meta-llama/Llama-3.2-3B-Instruct before continuing to execute the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMUxItHp1QJJ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import gc\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "pipe = None\n",
    "LLAMA_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "_tokenizer = None\n",
    "_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411,
     "referenced_widgets": [
      "a06f6d8b6f2243098071391bbdbd4f63",
      "e5817362e9ab4cad8323117fbec4eaf8",
      "ecb8762889ab424bbd4ef2cad2071d81",
      "8acc88ebe39c49f4a1d565bd2ca36256",
      "fdbda7ee25f5400eab38b57c577bcd82",
      "3da0a5f3d19c460d95912838dac659dc",
      "d1d6d82ca5044d5188ef21468bdc1f36",
      "c746dc410b8c4c739ed194f00ebc5dfc",
      "e4b9b9c6ec27443fa06506b426a29169",
      "d9e6368fcf094b479e38743e5bd49877",
      "925250b1cf50433f9d525f8426b0f27a",
      "2ebf88f5457343578e112a501427b501",
      "0bef94324fab464aa140ae99b032f0cd",
      "2550adafe53f49718077460574ad4f4a",
      "dd3233d5b75e419489368bbb69d73e63",
      "73b09a516c434fadae38b393951dcdbd",
      "0443b17501b34800918ef23c70ca89a1",
      "c342e83130c0492486c5844b2fd74525",
      "8f006485a00449658c25c58ecd23dbcf",
      "dbefbf319dc840439069361970af540f",
      "c7caa49d269a416b8533769e4c80806b",
      "1c097d6dd7254a0eaa0f3a86220b3be5",
      "c13c713c82954eeea0c347673d7c3882",
      "33453bfe6e824b0c9564c2df25e5880b",
      "4e303992ebba499f8c9130ea252e7f13",
      "0817d08b850c45679edc874888abb9d5",
      "60da5564a705435c8c4ae57dfe877e84",
      "8827b87e5d4a4ca182785b5f25f9bb4d",
      "706f087f813c43359d4bc5f0cbd72153",
      "87e6630dbe8a4a51bd2a1052e4311ca3",
      "508905f80b954643bd8aa1bd9cb9873d",
      "2cc0434afd6444f9985c633cbca9611b",
      "fdc6c007da404fceadb3d85c57cc7b97",
      "aff29e4a975c4e91be0ea4acbbe4fc13",
      "c64ff2da8bd54d929224fce9867a21ac",
      "03ef59ca79ed4e2f87e4917bd94af11a",
      "99ff76b35cd24cf4aa7bb5438a181fcd",
      "94168946dac146098d4228b1b4be2e01",
      "5a62ff928dd4466aa0aafaeb0fd6edff",
      "e2a04f76dfc74245b4654693b1ff4ab4",
      "bdc27dbb0016423390fa6776f46260f6",
      "d6931920520b4b3681de9271c1b29018",
      "f26d0008c40948439eb4b4df759b71a5",
      "33ae1d14b9f548b1a943fc66fa3b1da8",
      "93e722689fd648f6b0356ae10506a360",
      "0e47e302f4144743bb481bcc852f73a2",
      "04f8d80b17a14d30afc4ce4b8dc1270c",
      "f4c3e89dd9f24ff683ac6eea06dac14a",
      "2caa57ffc92e47ac9d645ec64cd11e1f",
      "13538c154cf74d828d5b3ede73d6bbe1",
      "6e1ac3d5804a45f69f73da212e6bf4f5",
      "137857ed42e94c30bfaa6721af3fe502",
      "7ebe0cdbce9242449dfb27b940913fb7",
      "2c85e26c62d64c0eac76485c09313bbc",
      "075a6daa48054930a806491779821df8",
      "ba983cb883f74cf8bec7bb5f2d504ddf",
      "d2be5f57496e4ab4a81e92b96606b168",
      "489de1e427934ae392fe9eaf75dd54a3",
      "15db5f18162d47b5aa8c169f5b0484ad",
      "d77d5b29ee8747399704074292d9a67c",
      "9194659ac4274dc8adf77b07c0b65960",
      "6d628bfedadc4d0cb73df0bb8013fa20",
      "808053f8f9af45cdac4fde834472d2af",
      "1a70478a113b4ff3a995d14bee8a0b2b",
      "cd1bc7a848514218a004f3a8c8584b5b",
      "f8c0737e27264ae891f271f8ac573c7e",
      "8e7e8c33252e4e35932413e47641f682",
      "3ec3ea19d18b42b3912baa8e90e61cf6",
      "59eba37d7c5741b8823fdc8c6fa52999",
      "76b4d1876d0f4af987fb5c2094bc15b2",
      "8a1fcf2d2d6a43308d9cc54614126f36",
      "f5b9bd1546f14866b89f0fec381b99b4",
      "d3677658f9b24f6898409ae55212607d",
      "96157e2bec6c4c6fbe1d2a5ba5ac017f",
      "210da0d846be49e1905c6bcbb1f8337a",
      "f2ad6e2ca0714e9c94d9e446d549b28d",
      "0bda110ca7da4e418794556ec046dee9",
      "f45f819839e740de9ef5fefc77242367",
      "26318140b16a4a7cb0c0fd960444689d",
      "5506265a2e9542d6a45f0d793f9fcaab",
      "e65d439ce7f845eea97948dd9ca2c42a",
      "b17066dd2e9245ffb760bbea0545599a",
      "3761a1e23c4843b68e262cf3dda379c0",
      "b114013846c841b6b66b13cbc650d02a",
      "837feaca3f544fc98253fbf52e2d9dcf",
      "36bff2d6f0974016a4bc86fe7c51f2d4",
      "46f43fc301ab4ace9062b74ccfd1abbc",
      "76e86824f92c481ca6ded21977ad6310",
      "c3c637270d6b4453a8317f4d7bfa2f76",
      "b57b535c7e4347d8a362291353090531",
      "1ef6618640344588833477c398fdcedc",
      "f6cc1814f09f4fb286b49f95e51e5c01",
      "c8695c7d019f482e91f1486a9b2603e2",
      "9eb54d3da23b45fd9c35694653e092bc",
      "61133bde66c546c58f173aa75f8399bb",
      "c733337511844ef78da65c56ff8ee239",
      "396588ca4140452db95b52f1156f7afe",
      "5873ff4d9f3e4865ac112abc78b5e1ec",
      "802aae8615644e32a52bdd3e90c1f701",
      "13871db6ca3f4c70b51a451b2fb23898",
      "add24c6402e543cfbca13a9aee3e4d6a",
      "544fd27facb64630a09fe35808a28532",
      "42a30219dd1f4db78dc1b75de9e79857",
      "836fae3c93b244e38db6ea76354121e3",
      "1bc7b144b3204435b852d2f9ae1f40ce",
      "d84c740aa323430fa73c47541d8d0101",
      "127ca5a7eb194855818682c068f6b9d3",
      "971645db1cf841db8befdd1df41528ba",
      "0408bc8b2c3e427e90197a85f85ac05b",
      "dab88871d48e4ed795f0eabfa68a5b08"
     ]
    },
    "id": "fwQ8ujFwwQUT",
    "outputId": "8739a55c-1a5e-448c-a0aa-eabe481c47cb"
   },
   "outputs": [],
   "source": [
    "def get_llama_model():\n",
    "    global _tokenizer, _model\n",
    "\n",
    "    if _tokenizer is not None and _model is not None:\n",
    "        return _tokenizer, _model\n",
    "\n",
    "    print(\"Loading Llama model once...\")\n",
    "\n",
    "    _tokenizer = AutoTokenizer.from_pretrained(LLAMA_MODEL, padding_side=\"left\")\n",
    "    _tokenizer.pad_token = _tokenizer.eos_token\n",
    "\n",
    "    _model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLAMA_MODEL,\n",
    "        device_map=\"cuda\",\n",
    "    )\n",
    "\n",
    "    _model.eval()\n",
    "    return _tokenizer, _model\n",
    "\n",
    "def unload_llama():\n",
    "    global _tokenizer, _model\n",
    "    del _tokenizer\n",
    "    del _model\n",
    "    _tokenizer = None\n",
    "    _model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def build_chat_batch(sentences, tokenizer):\n",
    "    prompts = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You rewrite sentences in a casual, natural, human way. Avoid AI-like phrasing. \"\n",
    "                    \"You rewrite ONLY the user’s sentence. \"\n",
    "                    \"Do not ask questions. Do not respond conversationally. Output ONLY the rewritten sentence, nothing more.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sentence,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # Apply template to ONE conversation at a time\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    # Now batch tokenize all prompts\n",
    "    encoded = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def extract_assistant_response(text):\n",
    "    # Llama 3 / Meta chat template — last assistant header\n",
    "    if \"<|start_header_id|>assistant<|end_header_id|>\" in text:\n",
    "        text = text.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip()\n",
    "\n",
    "    # Fallback: split on literal \"assistant\\n\\n\"\n",
    "    elif \"assistant\" in text:\n",
    "        parts = text.split(\"assistant\")\n",
    "        text = parts[-1].strip()\n",
    "\n",
    "    # Remove stray template tokens\n",
    "    for bad in [\"<|eot_id|>\", \"<|start_header_id|>\", \"<|end_header_id|>\"]:\n",
    "        text = text.replace(bad, \"\").strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def paraphrase_batch(sentences, max_new_tokens=60):\n",
    "    tokenizer, model = get_llama_model()\n",
    "\n",
    "    inputs = build_chat_batch(sentences, tokenizer).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode entire batch\n",
    "    batch_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    results = []\n",
    "    for text in batch_text:\n",
    "        clean = extract_assistant_response(text)\n",
    "        results.append(clean)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# count changed token by longest similar subsequence\n",
    "import difflib\n",
    "def count_token_replacements(original, paraphrased):\n",
    "    orig_tokens = nltk.word_tokenize(original)\n",
    "    para_tokens = nltk.word_tokenize(paraphrased)\n",
    "\n",
    "    matcher = difflib.SequenceMatcher(None, orig_tokens, para_tokens)\n",
    "\n",
    "    replaced = 0\n",
    "    for opcode, a0, a1, b0, b1 in matcher.get_opcodes():\n",
    "        if opcode in (\"replace\", \"delete\", \"insert\"):\n",
    "            replaced += max(a1 - a0, b1 - b0)\n",
    "    return replaced\n",
    "\n",
    "def paraphrase_attack_llama(text, replacement_rate=0.1, batch_size=8):\n",
    "\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    n_total = len(sentences)\n",
    "    n_replace = max(1, int(n_total * replacement_rate))\n",
    "\n",
    "    indices = set(random.sample(range(n_total), n_replace))\n",
    "\n",
    "    to_paraphrase = []\n",
    "    positions = []\n",
    "\n",
    "    # Collect sentences to paraphrase\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if i in indices:\n",
    "            to_paraphrase.append(sent)\n",
    "            positions.append(i)\n",
    "\n",
    "    # Batch paraphrase\n",
    "    new_sentences = paraphrase_batch(to_paraphrase)\n",
    "\n",
    "    # Insert results back\n",
    "    replacements_made = 0\n",
    "    out_sentences = sentences.copy()\n",
    "\n",
    "    for pos, old, new in zip(positions, to_paraphrase, new_sentences):\n",
    "        out_sentences[pos] = new\n",
    "        replacements_made += count_token_replacements(old, new)\n",
    "\n",
    "    return \" \".join(out_sentences), replacements_made\n",
    "\n",
    "text = \"The cat sat on the mat. The weather is bad. I can clean up your entire script into a ready-to-run file.\"\n",
    "paraphrased_text = paraphrase_attack_llama(text, replacement_rate = 1)\n",
    "print(text)\n",
    "print(paraphrased_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_Fwp0340o7u",
    "outputId": "0f91cf00-4521-4f8f-f080-f5c996c80494"
   },
   "outputs": [],
   "source": [
    "text = \"The cat sat on the mat. Just tell me and I’ll adapt it. I can clean up your entire script into a ready-to-run file.\"\n",
    "paraphrased_text = paraphrase_attack_llama(text, replacement_rate = 0.5)\n",
    "print(text)\n",
    "print(paraphrased_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaztH-ihIHVm"
   },
   "outputs": [],
   "source": [
    "unload_llama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_ovl1roxm90"
   },
   "source": [
    "## Apply Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HP3D8m_Vtg4h",
    "outputId": "deaeaf7a-9700-447c-b53d-f117e9e30690"
   },
   "outputs": [],
   "source": [
    "def apply_attack_to_dataset(\n",
    "    input_file,\n",
    "    output_file,\n",
    "    attack_function,\n",
    "    replacement_rate=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply attack to Fast-DetectGPT dataset (raw_data.json format)\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    with open(input_file, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    attacked_dataset = {\n",
    "        'sampled': [],\n",
    "        'original': dataset.get('original', [])\n",
    "    }\n",
    "\n",
    "    stats = {\n",
    "        'total_samples': 0,\n",
    "        'total_tokens_original': 0,\n",
    "        'total_tokens_replaced': 0,\n",
    "        'successful_attacks': 0\n",
    "    }\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    for original_text in tqdm(dataset['sampled'], desc=\"Applying attack\", unit=\"sample\"):\n",
    "        # Apply attack\n",
    "        attacked_text, num_replaced = attack_function(\n",
    "            original_text,\n",
    "            replacement_rate\n",
    "        )\n",
    "\n",
    "        attacked_dataset['sampled'].append(attacked_text)\n",
    "\n",
    "        # Track statistics\n",
    "        original_tokens = len(nltk.word_tokenize(original_text))\n",
    "        stats['total_samples'] += 1\n",
    "        stats['total_tokens_original'] += original_tokens\n",
    "        stats['total_tokens_replaced'] += num_replaced\n",
    "        if num_replaced > 0:\n",
    "            stats['successful_attacks'] += 1\n",
    "\n",
    "    # Save attacked dataset\n",
    "    output_path = Path(output_file)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(attacked_dataset, f, indent=2)\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"✓ Attacked dataset saved to {output_file}\")\n",
    "    print(f\"\\n=== Attack Statistics ===\")\n",
    "    print(f\"Total samples processed: {stats['total_samples']}\")\n",
    "    print(f\"Successful attacks: {stats['successful_attacks']}\")\n",
    "    print(f\"Total original tokens: {stats['total_tokens_original']}\")\n",
    "    print(f\"Total tokens replaced: {stats['total_tokens_replaced']}\")\n",
    "    print(f\"Actual replacement rate: {stats['total_tokens_replaced']/stats['total_tokens_original']:.2%}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "# ===========================================\n",
    "# MAIN EXPERIMENT\n",
    "# ===========================================\n",
    "\n",
    "dataset = \"xsum\"\n",
    "source_model = \"gpt-neo-2.7B\"\n",
    "attack_pct = 0.5\n",
    "\n",
    "# Define paths (update base path to your environment)\n",
    "base_path = \"exp_main/data\"\n",
    "input_file = f\"{base_path}/{dataset}_{source_model}.raw_data.json\"\n",
    "\n",
    "# Test different attack strategies\n",
    "attack_strategies = [\n",
    "    (\"synonym\", synonym_attack),\n",
    "    (\"strategic\", strategic_perturbation_attack),\n",
    "    (\"paraphrase\", paraphrase_attack_llama)\n",
    "]\n",
    "\n",
    "print(\"Starting adversarial attack experiment...\\n\")\n",
    "\n",
    "\n",
    "for attack_name, attack_func in attack_strategies:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running {attack_name.upper()} attack\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    output_file = f\"{base_path}/{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct.raw_data.json\"\n",
    "\n",
    "    stats = apply_attack_to_dataset(\n",
    "        input_file,\n",
    "        output_file,\n",
    "        attack_func,\n",
    "        replacement_rate = attack_pct\n",
    "    )\n",
    "\n",
    "    print(f\"\\nOutput saved: {output_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All attacks completed!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBF_H5vdxrGN"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFrcF3PP11j"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6hnLFY5PzuZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "def get_roc_metrics(real_preds, sample_preds):\n",
    "    \"\"\"\n",
    "    Compute FPR, TPR, and AUROC given scores for real (label 0)\n",
    "    and sample/attacked (label 1) texts.\n",
    "    \"\"\"\n",
    "    labels = [0] * len(real_preds) + [1] * len(sample_preds)\n",
    "    scores = real_preds + sample_preds\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return fpr.tolist(), tpr.tolist(), float(roc_auc)\n",
    "\n",
    "def get_precision_recall_metrics(real_preds, sample_preds):\n",
    "    \"\"\"\n",
    "    Compute Precision, Recall, and PR-AUC for the same setting.\n",
    "    \"\"\"\n",
    "    labels = [0] * len(real_preds) + [1] * len(sample_preds)\n",
    "    scores = real_preds + sample_preds\n",
    "    precision, recall, _ = precision_recall_curve(labels, scores)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return precision.tolist(), recall.tolist(), float(pr_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jNVD6ytZMPQ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def get_auroc_from_json(result_file):\n",
    "    \"\"\"\n",
    "    Read a Fast-DetectGPT results JSON and return AUROC.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(result_file):\n",
    "        print(f\"[WARN] Results file not found: {result_file}\")\n",
    "        return None\n",
    "    with open(result_file, \"r\") as f:\n",
    "        res = json.load(f)\n",
    "    return res[\"metrics\"][\"roc_auc\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHmtakQoP4Qx"
   },
   "source": [
    "## Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUE8y7cU17YU",
    "outputId": "5252994e-9085-4765-aa95-101b4b900d2a"
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Running synonym attack evaluation ===\")\n",
    "\n",
    "dataset = \"xsum\"\n",
    "source_model = \"gpt-neo-2.7B\"\n",
    "scoring_model = \"gpt-neo-2.7B\"\n",
    "\n",
    "for attack_name, _ in attack_strategies:\n",
    "    !python scripts/fast_detect_gpt.py \\\n",
    "        --sampling_model_name {sampling_model} \\\n",
    "        --scoring_model_name {scoring_model} \\\n",
    "        --dataset {dataset} \\\n",
    "        --dataset_file exp_main/data/{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct \\\n",
    "        --output_file exp_main/results/{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPZb5Qu62kew",
    "outputId": "59e711b8-e878-46b6-ad5c-b2da3b09251f"
   },
   "outputs": [],
   "source": [
    "attack_strategies = [\n",
    "    (\"synonym\", synonym_attack),\n",
    "    (\"strategic\", strategic_perturbation_attack),\n",
    "    (\"paraphrase\", paraphrase_attack_llama)\n",
    "]\n",
    "\n",
    "for attack_name, _ in attack_strategies:\n",
    "    summarize_performance(f'/content/fast-detect-gpt/exp_main/results/{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct.sampling_discrepancy.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sw8L7_dIZT_F"
   },
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ITppdyrZVzM",
    "outputId": "b62281fd-90fd-4fcc-b8d3-c3a0ff19cde2"
   },
   "outputs": [],
   "source": [
    "dataset      = \"xsum\"\n",
    "source_model = \"gpt-neo-2.7B\"\n",
    "attack_pct   = attack_pct   # whatever you used above\n",
    "\n",
    "# 1. Baseline Fast-DetectGPT (no attack), from your baseline dir:\n",
    "baseline_file = (\n",
    "    \"./baseline/exp_gpt3to4/results/\"\n",
    "    f\"{dataset}_gpt-3.5-turbo.{source_model}_{source_model}.sampling_discrepancy.json\"\n",
    ")\n",
    "baseline_auroc = get_auroc_from_json(baseline_file)\n",
    "\n",
    "# 2. Attacked Fast-DetectGPT runs\n",
    "attack_strategies = [\n",
    "    (\"synonym\",   \"synonym\"),\n",
    "    (\"strategic\", \"strategic_perturbation\"),\n",
    "    (\"paraphrase\",\"paraphrase_llama\"),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for attack_name, _ in attack_strategies:\n",
    "    res_file = (\n",
    "        f\"exp_main/results/\"\n",
    "        f\"{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct.sampling_discrepancy.json\"\n",
    "    )\n",
    "    auroc = get_auroc_from_json(res_file)\n",
    "    rows.append((attack_name, auroc))\n",
    "\n",
    "print(\"=== AUROC for GPT-Neo-2.7B on XSum ===\")\n",
    "print(f\"Baseline (no attack): {baseline_auroc:.4f}\" if baseline_auroc is not None else \"Baseline: N/A\")\n",
    "for attack_name, auroc in rows:\n",
    "    if auroc is None:\n",
    "        print(f\"{attack_name:10s}: N/A (file missing)\")\n",
    "        continue\n",
    "    drop = baseline_auroc - auroc if baseline_auroc is not None else None\n",
    "    print(f\"{attack_name:10s}: {auroc:.4f}\", end=\"\")\n",
    "    if drop is not None:\n",
    "        print(f\"  (Δ AUROC = {drop:+.4f})\")\n",
    "    else:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aSX1PO-ZZE1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def summarize_result_file(result_file):\n",
    "    \"\"\"\n",
    "    Mimic show_result.py for a single Fast-DetectGPT JSON.\n",
    "    \"\"\"\n",
    "    with open(result_file, \"r\") as f:\n",
    "        res = json.load(f)\n",
    "\n",
    "    if \"metrics\" not in res:\n",
    "        print(f\"{result_file}: metrics not found.\")\n",
    "        return\n",
    "\n",
    "    n_samples = res[\"info\"][\"n_samples\"]\n",
    "    roc_auc   = res[\"metrics\"][\"roc_auc\"]\n",
    "    real      = np.array(res[\"predictions\"][\"real\"])\n",
    "    samples   = np.array(res[\"predictions\"][\"samples\"])\n",
    "\n",
    "    print(f\"{os.path.basename(result_file)}:\")\n",
    "    print(f\"  n_samples = {n_samples}\")\n",
    "    print(f\"  ROC AUC   = {roc_auc:.4f}\")\n",
    "    print(f\"  real      = mean {real.mean():.2f}, std {real.std():.2f}\")\n",
    "    print(f\"  samples   = mean {samples.mean():.2f}, std {samples.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gj6SjUiJZbI3",
    "outputId": "c79d3513-f955-4a93-dc21-66c1d7e8f782"
   },
   "outputs": [],
   "source": [
    "summarize_result_file(baseline_file)\n",
    "for attack_name, _ in attack_strategies:\n",
    "    res_file = (\n",
    "        f\"exp_main/results/\"\n",
    "        f\"{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct.sampling_discrepancy.json\"\n",
    "    )\n",
    "    summarize_result_file(res_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xN6EIQ6UvVUc"
   },
   "source": [
    "### Bar chart: AUROC drop per attack strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "v1eb-UbFvXOS",
    "outputId": "1d3a249b-0243-4303-f0f2-68456de9842d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "labels = [\"baseline\", \"synonym\", \"strategic\", \"paraphrase\"]\n",
    "aurocs = [baseline_auroc] + [auroc for _, auroc in rows]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(labels, aurocs)\n",
    "\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.title(\"Fast-DetectGPT AUROC on XSum (GPT-Neo-2.7B)\")\n",
    "\n",
    "# Annotate bars with exact values\n",
    "for bar, value in zip(bars, aurocs):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 0.02,\n",
    "        f\"{value:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IWLZf3Cvgde"
   },
   "source": [
    "### Score distributions: histograms of real vs samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuQBZ3qPvjty"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_score_histogram(result_file, title=None, bins=40):\n",
    "    \"\"\"\n",
    "    Plot histogram of Fast-DetectGPT scores for real vs samples\n",
    "    from a single results JSON.\n",
    "    \"\"\"\n",
    "    with open(result_file, \"r\") as f:\n",
    "        res = json.load(f)\n",
    "\n",
    "    real = np.array(res[\"predictions\"][\"real\"])\n",
    "    samples = np.array(res[\"predictions\"][\"samples\"])\n",
    "    roc_auc = res[\"metrics\"][\"roc_auc\"]\n",
    "    n_samples = res[\"info\"][\"n_samples\"]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Real (label 0)\n",
    "    plt.hist(\n",
    "        real,\n",
    "        bins=bins,\n",
    "        alpha=0.6,\n",
    "        density=True,\n",
    "        label=f\"Real (mean={real.mean():.2f}, std={real.std():.2f})\",\n",
    "    )\n",
    "\n",
    "    # Samples (label 1)\n",
    "    plt.hist(\n",
    "        samples,\n",
    "        bins=bins,\n",
    "        alpha=0.6,\n",
    "        density=True,\n",
    "        label=f\"Samples (mean={samples.mean():.2f}, std={samples.std():.2f})\",\n",
    "    )\n",
    "\n",
    "    if title is None:\n",
    "        title = os.path.basename(result_file)\n",
    "    plt.title(f\"{title}\\nAUROC = {roc_auc:.3f}, n={n_samples}\")\n",
    "    plt.xlabel(\"Fast-DetectGPT score\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Il82WwBzvrVT",
    "outputId": "4d5ad4f5-1bf2-40a8-ef5f-f11e5e5e79f1"
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "plot_score_histogram(\n",
    "    baseline_file,\n",
    "    title=\"Baseline: GPT-3.5-turbo vs GPT-Neo-2.7B on XSum\",\n",
    ")\n",
    "\n",
    "# Attacked configs\n",
    "for attack_name, _ in attack_strategies:\n",
    "    res_file = (\n",
    "        f\"exp_main/results/\"\n",
    "        f\"{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct.sampling_discrepancy.json\"\n",
    "    )\n",
    "    plot_score_histogram(\n",
    "        res_file,\n",
    "        title=f\"Attack: {attack_name} ({int(attack_pct * 100)}%)\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QplUUGgIMnNT"
   },
   "source": [
    "## Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "68e590c2c65540e58ced49065f3622bd",
      "9c144d3b09804e778b0b210c93e11be1",
      "52a5d8cd51cb485394a6ef2ffec0dcb9",
      "0c7254400866440c8076110fd8c3c34d",
      "2aa1526c98284a6ca7c5f9f1f2df2389",
      "fec6f033643a4676add0d87aad328ecf",
      "a9080561955a47ff9d4e808c9c9fa144",
      "25934a72b0e94244b4d5b13e20047235",
      "aea1988749cd456d972565cc5c18b3cb",
      "84552a3f2c7f4dd3b0c3de74dca7f61c",
      "37aa6d8227ef40efaf894cbe66397042",
      "dc20a60c58144ccaa5847bdaac7d4a26",
      "a06c0801141d4e7d83c92f5b876fe62c",
      "fcf7d986ee0a4e18857cc0524ed3c989",
      "5e4fce1928fa45e7982ff98ba4653a31",
      "ad4d65dc15684001bd15074dab290934",
      "5247f70e848e4318b1fc8d72150d79be",
      "b2a85f54545e4a1dbb5c29e0c13672c6",
      "9a2f04f61005469abd53290a7ac33890",
      "17b988c84d3247888e1953593f925e67",
      "57b1c1a4e26c45268fdaf73254b118c3",
      "a93a925b304049cb88f0aa1f6176c92c",
      "ea75b636db6f44bd8b6409cc49b2a18a",
      "58d5c5e3dec8496bb0386a4d209ecad7",
      "c068cb4e82954e1a9303e66a4f4d94b9",
      "4c6c0715d66e4d2681d87752f9090d3d",
      "49bfefbb05c94bd39fa16dc58756e2d3",
      "58f00ee5cc304ea5ba577af594768b12",
      "3cc35cfea49b4b09921f1aef04943dba",
      "bce1659f9e0b4166b5cd9f616e5e480a",
      "1da7c54dca8d42b8a6388ddc8e717a67",
      "743679b6ae4e4b4389f574939628ab42",
      "0792cbdb177449c890a7de6185cb809c",
      "c1aac235ae1b4cd5831b7ae9c28faa95",
      "2db830e680e64c59adda5e83ec63f3bf",
      "a1ee3381334b46deba2d5e802f00a2a2",
      "90107e8bbf62479d9a37f50eb194e343",
      "48db481b60124e43a92373173497f44c",
      "e218143e81d94f349b4c1ec47b392499",
      "3aa6904b55304f5a906c83d01e140cb7",
      "402d9e56d40d49e3a069046424d8d507",
      "7b1022d46980453187e2b1c7601f259e",
      "f7907c88474d41dc9335c9617e6f9e1d",
      "bd3ca7c77ece42e3bae32501cdc15c9e",
      "b64166b98d2c43549486ff462a8053ff",
      "f026c05e9c144420b93c773250796ba8",
      "6475d54ec25447c1b434e133accfe972",
      "85c503b0f1f9434eaed0df9e257065cd",
      "1add874c9d1c42ecb8b898921f87b77f",
      "359558c1b2e54bb98c715b023783df4a",
      "06eb4b09f9064c5f999cda63bfdefae1",
      "5fb98ea04d664f1d9ca43e3d5901658d",
      "ea021c32bd784d1284a0d36b6240affc",
      "49d372dc54e24d8580052c86247c9879",
      "a1e79d576b614429992e4c099fcdb416",
      "5b560e319e12441892699eeef2c7e9a3",
      "5bd42093295f48128af81a31e34edfff",
      "e18e73a6ebce48528e4c03567dbcc1c7",
      "076af43b6a434f48b7f5e5a3ea519865",
      "ec310fba4e234d358baf9fb0ee105df2",
      "845201f7832f44d9ab6779a448983bc3",
      "5c6f2c82436648199dad55c149e97b39",
      "586bb187a2ab4b8da917a4f056d2fc4f",
      "ec1f0cf1ede14f72bc7f45ee49e1e9c5",
      "e68bed1779d14973875a2d31da69bc61",
      "a4a8c7e4f22347cd8e3e4038330d47e8",
      "8d4be1cd2b5a4348a08f38182ca0553e",
      "94370ce90a774b2cbfba57599deb12a9",
      "297633a8444e4ac181c1df0bb0f88b12",
      "64342db6e0564655b35a780453245b61",
      "d6dbe3ed22814298998e9c232cb36563",
      "313f8f2e10144cfbb4526051af2c48d6",
      "00132fd3ebb84f5fb6b6fcd478701c6f",
      "c3ad991936264e138717f65779d97e46",
      "2dffe67e7fa945f6b33062aab6337c7d",
      "1f25a674cd7547a2a293f00bf0dfa55f",
      "a151403a4e23451e815a8fd5008ba7c3",
      "9445e90b2dc8461ba1b29cf17217acfb",
      "c6aaf6bedda64e999849dac92b17434a",
      "b0aaecd3d50f4fed89e8863f68891283",
      "8b4a67fb42bd4837b362fdf26889dc70",
      "bee2f714ecf54bd388cc9e602d729ae7",
      "838a5febbecf4848a4bacf0f4a3bc126",
      "35468c371b9d41ba993c32936c07f82a",
      "1784044773164516a5cbd8ed213730d5",
      "4a900bf4f24447959ca0bb11ca7ff52a",
      "a661eefa178f4944bed5916944bd22c6",
      "6990790c601b4830a63b58fcebfc3255",
      "6bab5c666ea74970962723371f1bd3ff",
      "018c5a41c5c240afa3cbe0562dacec4c",
      "a1f6bb87aa00446a89450752f6ff982d",
      "bb7095eab24f4de28e7ec9950d482a55",
      "cc9d651ba9a34695bca5cec097a09b0c",
      "4cede46abcf549b292eee5a827e066d0",
      "8ba7d4c6166c455da7d84fc658b235a8",
      "49222fa6b8e5430bac78cdf37b03b698",
      "bf36beaba6bc4807970fe491c5a551c4",
      "2219c50046ac4c2e849cd2d56023788d",
      "3503bdc22c7646bc9cde34b3ad0bb2ca",
      "880fc6111ba64253a26e4381e674f646",
      "ef91a4a75c5141acbc74e9a55b31a8cf",
      "a4858aa1556a44ff96ebf987c5deef0d",
      "fe272d8ed29a4c6aba7ace275cca6df9",
      "a98d72d670604abdb70e703ccfdf993d",
      "d2af6fb5d7b249c3b7ea5cb3fd9175fb",
      "3f5f897c060149b5a7b314eb85137cb8",
      "73de18b1e80c4c0ea2f4fedc555d059f",
      "a1383e90c2bb43b4a422218b14533920",
      "cf9c573c083a4de6bc2b5d10570033ef",
      "9f7c41a9a1884b8aaf1dd9e58c03ec5c",
      "20532d00219c4d4bb798ac52cf273200",
      "c63ab993b2ce4ac3a8701e0dcdcca9a0",
      "f5642aaf824c4cdd8ab678228b56c546",
      "34c5e3daf6ba42c0a9152916303fecfc",
      "2505421e5ccb48f796486e02ac24e918",
      "a73797eaefde459f8078a53296bf69bd",
      "0fa0643b62454841ad657df618def4ed",
      "68f2f0d4bd8147da9627264d7a6dddb5",
      "c2fa178dda40480184f043feec698e0e",
      "647d9c1b081040b99b90160533787ec3",
      "3d89e650a9ec409f8ef0355efc55af6d"
     ]
    },
    "id": "_Y3AFuaWNH60",
    "outputId": "e2e7ec51-a1c9-4075-8b57-113069909a6a"
   },
   "outputs": [],
   "source": [
    "# Install sentence-transformers package\n",
    "# Reference: https://sbert.net/\n",
    "!pip install -q sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load all-MiniLM-L6-v2 model: a small, fast model for a consine-similarity based consistency metric\n",
    "sem_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRcWcif2NcL-"
   },
   "source": [
    "### Computational function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUnCEkOTNbBO"
   },
   "outputs": [],
   "source": [
    "def compute_semantic_consistency(base_raw_file, attacked_raw_file):\n",
    "    \"\"\"\n",
    "    Compare sentence embeddings between original sampled[] (pre-attack)\n",
    "    and attacked sampled[] (post-attack).\n",
    "    \"\"\"\n",
    "    with open(base_raw_file, \"r\") as f:\n",
    "        base = json.load(f)\n",
    "    with open(attacked_raw_file, \"r\") as f:\n",
    "        atk = json.load(f)\n",
    "\n",
    "    base_texts = base[\"sampled\"]       # BEFORE attack\n",
    "    atk_texts  = atk[\"sampled\"]        # AFTER attack\n",
    "\n",
    "    assert len(base_texts) == len(atk_texts), \"Mismatch in sample count.\"\n",
    "\n",
    "    # Encode in batches\n",
    "    emb_base = sem_model.encode(base_texts, batch_size=32, convert_to_tensor=True, show_progress_bar=True)\n",
    "    emb_atk  = sem_model.encode(atk_texts, batch_size=32, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    # Compute cosine similarities pairwise\n",
    "    sims = util.cos_sim(emb_base, emb_atk).diagonal().cpu().numpy()\n",
    "    return sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Bja1E0LNhSR"
   },
   "source": [
    "### Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530,
     "referenced_widgets": [
      "66bb9990c95448be81369ffacb2b7353",
      "28a32b9101fc41fe85aa0f45833725c0",
      "f33f336ce0434df9a4a44fe53440d2fe",
      "c6c93f7e48bb4b42963a2df6b7d3bae9",
      "c42c59ecbd344f909740a19572ecac7b",
      "6b64d7aa02e548c5a0ab39ed47bfd2d4",
      "d20d70e04bce44d29d8e6c63bc174c35",
      "ee4e74366f804925a29658ad59367054",
      "e5f629c0dfe44af090676e5a9be39a65",
      "3de22a6d0791401e803ed055467aa590",
      "4ae8067073ef44a0ab5085155bf22ebb",
      "d94d720692ae415f9eb792731da1c517",
      "749fb3ab56db4e76bdc9dd0b35ff03ec",
      "92edccd4fa654c83a7a8809fa36bcf02",
      "c2935b0376d94fb8a8a32115506ac0ae",
      "48a8428246224ec79c6c40440b45e252",
      "ced6adefe589451993aad105906f358d",
      "47dfbb07f1e44739a33c773d93b5dbb2",
      "a8d9f1f3ac314338beb4000cb32873c0",
      "7055e67cffab41f18aadb2cbd75ee780",
      "4e92b42bf99b436c90323cd41a414159",
      "7ec19f376f754268b1d91b89e68f9f1f",
      "85dc79626853492ba5bbdb1462d3bc0d",
      "6f3aa68e9d9e4e1bbc1aaf0c74ee9954",
      "8bcfcf1890724ff9ace2fe81ea47805a",
      "3d4313607dd2464387252825f23dbddb",
      "7c914c0f97bb4607b0f9336db22edb22",
      "a4a1e49fbc3a4ba3932d76fbac7a80d7",
      "f75223b2397840ae9928cc60536f84a2",
      "192543620dd149788cdc68ce29088b08",
      "a8248e8692464127bb6b49f79bd0bd2e",
      "3b301c3d0c7e46bba8118a8f74bfb528",
      "bd599d1d26d24a3fb0ca66b33c3c4985",
      "37da3b6aa8144f32ab4bb35e98fe89e7",
      "9db67c865aed4cac9e1fb6a19d62174d",
      "9b69f41233a74a4f8b58958c613efd42",
      "40f00ae67e54428ca2d57f26ffd06e6b",
      "9ba76cc2575d43048d3bd879ba1c6241",
      "92e46f43e4ca40d7889e684511884076",
      "f95efeefa6614a01b6677ef74bbb3c62",
      "51ea2d71cf09468ca44cca4427d7edf0",
      "7547ba1037e84c07a08f5db40bf6e78c",
      "e5938981cbef4028a3426693a86fd858",
      "453dedbde0b548ec9dd72a5603bc8f11",
      "a83d396c37ad4a2082ddf4478dbf2a94",
      "716e51aff437425d95a6a535f01a09f3",
      "3a641653eb0547d682f412bf6b027805",
      "13f20493911d4a7c9310974a05cbac56",
      "f722ee3233544dc69a031c786d4a3a88",
      "9478287787f4489a82730211494e9ffd",
      "154fbd0f9ede43d9b9bad408d1d70a2a",
      "e0540f28ce7a49f1843c085c0f9dcdf6",
      "5dda167a2ad34c2f86563dbbd0c8d549",
      "729adb69deae4fab803c9ffc03975cec",
      "1b5962a2c25540fbbc2db92cfeacf45a",
      "ad979abe8c354e189966f2b80df6acb7",
      "8c8d04735ec74478916697823da3f6fe",
      "3805d550763c46c7896c75d41590a388",
      "4568dae3739647dba99e016a71d52ed6",
      "79a476f66f774eb09cd13126b28b2e82",
      "3e540d4aa7804f17a90b13003e21318e",
      "8961da2c48ca4668bd87333f458b0264",
      "36f05a7c9f04473fbd34ade2e51292ab",
      "c503923c02284dd3bf3384e1b886da96",
      "6c6e48121b674b78a4d55a6458d06932",
      "8c17c88bbf124492ad6ce962206c27c6"
     ]
    },
    "id": "k7naKrroNihC",
    "outputId": "3df956e7-d8c6-43c8-b155-239e15775858"
   },
   "outputs": [],
   "source": [
    "base_raw_data_file = f\"exp_main/data/{dataset}_{source_model}.raw_data.json\"\n",
    "\n",
    "semantic_results = {}\n",
    "\n",
    "for attack_name, _ in attack_strategies:\n",
    "    attacked_raw_file = (\n",
    "        f\"exp_main/data/\"\n",
    "        f\"{dataset}_{source_model}_attacked_{attack_name}_{int(attack_pct * 100)}pct.raw_data.json\"\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(attacked_raw_file):\n",
    "        print(f\"[WARN] Missing: {attacked_raw_file}\")\n",
    "        continue\n",
    "\n",
    "    sims = compute_semantic_consistency(base_raw_data_file, attacked_raw_file)\n",
    "    semantic_results[attack_name] = sims\n",
    "\n",
    "    print(f\"=== Semantic Consistency ({attack_name}, {int(attack_pct*100)}%) ===\")\n",
    "    print(f\"  n pairs     : {len(sims)}\")\n",
    "    print(f\"  mean sim    : {sims.mean():.3f}\")\n",
    "    print(f\"  median sim  : {np.median(sims):.3f}\")\n",
    "    print(f\"  min / max   : {sims.min():.3f} / {sims.max():.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0n8_6o6NjQC"
   },
   "source": [
    "### Visualize semantic analysis result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "JSV9_mQ-Nmrj",
    "outputId": "8a03b7e3-4ec3-4487-8dc4-82da20aa4b38"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for attack_name, sims in semantic_results.items():\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.hist(sims, bins=30, density=True, alpha=0.8)\n",
    "    plt.title(f\"Semantic consistency: {attack_name} ({int(attack_pct*100)}%)\\nMean={sims.mean():.3f}\")\n",
    "    plt.xlabel(\"Cosine similarity (original vs attacked)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
