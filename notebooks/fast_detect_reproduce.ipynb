{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Repo Clone and Env Setup"
      ],
      "metadata": {
        "id": "jqNJ59H5IKX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone fast-detect repo"
      ],
      "metadata": {
        "id": "mOuV8TOdITD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvx2xhxM54yG",
        "outputId": "e98826bb-3ac6-4c25-bfc8-5258765d6cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast-detect-gpt'...\n",
            "remote: Enumerating objects: 762, done.\u001b[K\n",
            "remote: Counting objects: 100% (264/264), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 762 (delta 240), reused 209 (delta 209), pack-reused 498 (from 1)\u001b[K\n",
            "Receiving objects: 100% (762/762), 226.69 MiB | 17.01 MiB/s, done.\n",
            "Resolving deltas: 100% (574/574), done.\n",
            "Updating files: 100% (503/503), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/baoguangsheng/fast-detect-gpt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-detect-gpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX6XEax_5-H9",
        "outputId": "cf2b1ecf-d7b6-49b0-e9c6-3dcdd2eb0617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast-detect-gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "-GS8NEdBIXHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependent packages"
      ],
      "metadata": {
        "id": "jQgtY7djIbmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy transformers datasets matplotlib tqdm openai nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJi2xJkx723e",
        "outputId": "36a0cfc9-2cdb-40f0-b7d7-e70144f95c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://sh.rustup.rs -sSf | sh -s -- -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj61VaLu6WHa",
        "outputId": "59d2ecb5-c64e-4a58-d062-67afcbe2b788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mprofile set to 'default'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[0m\u001b[1minfo: \u001b[0msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mlatest update on 2025-09-18, rust version 1.90.0 (1159e78c4 2025-09-14)\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'cargo'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'clippy'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rust-docs'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rust-std'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rustc'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rustfmt'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'cargo'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'clippy'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rust-docs'\n",
            " 20.5 MiB /  20.5 MiB (100 %)   8.0 MiB/s in  2s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rust-std'\n",
            " 27.8 MiB /  27.8 MiB (100 %)  10.3 MiB/s in  4s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rustc'\n",
            " 78.7 MiB /  78.7 MiB (100 %)  11.1 MiB/s in  7s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rustfmt'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[0m\u001b[1m\u001b[0m\u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[0m - rustc 1.90.0 (1159e78c4 2025-09-14)\n",
            "\n",
            "\u001b[0m\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[0m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[0m\u001b[1mPATH\u001b[0m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, you need to source\n",
            "the corresponding \u001b[0m\u001b[1menv\u001b[0m file under $HOME/.cargo.\n",
            "\n",
            "This is usually done by running one of the following (note the leading DOT):\n",
            ". \"$HOME/.cargo/env\"            # For sh/bash/zsh/ash/dash/pdksh\n",
            "source \"$HOME/.cargo/env.fish\"  # For fish\n",
            "source $\"($nu.home-path)/.cargo/env.nu\"  # For nushell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modify local_infer.py for Colab"
      ],
      "metadata": {
        "id": "X5bbm1aNIg_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/local_infer.py\n",
        "# Copyright (c) Guangsheng Bao.\n",
        "#\n",
        "# This source code is licensed under the MIT license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import json\n",
        "from model import load_tokenizer, load_model\n",
        "from fast_detect_gpt import get_sampling_discrepancy_analytic\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Considering balanced classification that p(D0) equals to p(D1), we have\n",
        "# p(D1|x) = p(x|D1) / (p(x|D1) + p(x|D0))\n",
        "def compute_prob_norm(x, mu0, sigma0, mu1, sigma1):\n",
        "    pdf_value0 = norm.pdf(x, loc=mu0, scale=sigma0)\n",
        "    pdf_value1 = norm.pdf(x, loc=mu1, scale=sigma1)\n",
        "    prob = pdf_value1 / (pdf_value0 + pdf_value1)\n",
        "    return prob\n",
        "\n",
        "class FastDetectGPT:\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.criterion_fn = get_sampling_discrepancy_analytic\n",
        "        self.scoring_tokenizer = load_tokenizer(args.scoring_model_name, args.cache_dir)\n",
        "        self.scoring_model = load_model(args.scoring_model_name, args.device, args.cache_dir)\n",
        "        self.scoring_model.eval()\n",
        "        if args.sampling_model_name != args.scoring_model_name:\n",
        "            self.sampling_tokenizer = load_tokenizer(args.sampling_model_name, args.cache_dir)\n",
        "            self.sampling_model = load_model(args.sampling_model_name, args.device, args.cache_dir)\n",
        "            self.sampling_model.eval()\n",
        "\n",
        "        distrib_params = {\n",
        "            'gpt-j-6B_gpt-neo-2.7B': {'mu0': 0.2713, 'sigma0': 0.9366, 'mu1': 2.2334, 'sigma1': 1.8731},\n",
        "            'gpt-neo-2.7B_gpt-neo-2.7B': {'mu0': -0.2489, 'sigma0': 0.9968, 'mu1': 1.8983, 'sigma1': 1.9935},\n",
        "            'falcon-7b_falcon-7b-instruct': {'mu0': -0.0707, 'sigma0': 0.9520, 'mu1': 2.9306, 'sigma1': 1.9039},\n",
        "        }\n",
        "        key = f'{args.sampling_model_name}_{args.scoring_model_name}'\n",
        "\n",
        "        # Fallback for KeyError\n",
        "        if key not in distrib_params:\n",
        "            print(f\"Warning: Key '{key}' not in distrib_params. Using 'gpt-neo-2.7B_gpt-neo-2.7B' as fallback.\")\n",
        "            key = 'gpt-neo-2.7B_gpt-neo-2.7B'\n",
        "\n",
        "        self.classifier = distrib_params[key]\n",
        "\n",
        "    # compute conditional probability curvature\n",
        "    def compute_crit(self, text):\n",
        "        tokenized = self.scoring_tokenizer(text, truncation=True, return_tensors=\"pt\", padding=True, return_token_type_ids=False).to(self.args.device)\n",
        "        labels = tokenized.input_ids[:, 1:]\n",
        "        if labels.size(1) == 0: # Handle empty or single-token text\n",
        "            return float('nan'), 0\n",
        "        with torch.no_grad():\n",
        "            logits_score = self.scoring_model(**tokenized).logits[:, :-1]\n",
        "            if self.args.sampling_model_name == self.args.scoring_model_name:\n",
        "                logits_ref = logits_score\n",
        "            else:\n",
        "                tokenized = self.sampling_tokenizer(text, truncation=True, return_tensors=\"pt\", padding=True, return_token_type_ids=False).to(self.args.device)\n",
        "                assert torch.all(tokenized.input_ids[:, 1:] == labels), \"Tokenizer is mismatch.\"\n",
        "                logits_ref = self.sampling_model(**tokenized).logits[:, :-1]\n",
        "            crit = self.criterion_fn(logits_ref, logits_score, labels)\n",
        "        return crit, labels.size(1)\n",
        "\n",
        "    # compute probability\n",
        "    def compute_prob(self, text):\n",
        "        crit, ntoken = self.compute_crit(text)\n",
        "        if np.isnan(crit):\n",
        "            return float('nan'), crit, ntoken\n",
        "        mu0 = self.classifier['mu0']\n",
        "        sigma0 = self.classifier['sigma0']\n",
        "        mu1 = self.classifier['mu1']\n",
        "        sigma1 = self.classifier['sigma1']\n",
        "        prob = compute_prob_norm(crit, mu0, sigma0, mu1, sigma1)\n",
        "        return prob, crit, ntoken\n",
        "\n",
        "# --- NEW VERSION with Command-Line Text Input ---\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--text', type=str, required=True, help='Text to be analyzed.')\n",
        "    parser.add_argument('--sampling_model_name', type=str, default=\"gpt-neo-2.7B\")\n",
        "    parser.add_argument('--scoring_model_name', type=str, default=\"gpt-neo-2.7B\")\n",
        "    parser.add_argument('--device', type=str, default=\"cuda\")\n",
        "    parser.add_argument('--cache_dir', type=str, default=\"../cache\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # 1. Initialize the detector\n",
        "    print(\"Initializing detector...\")\n",
        "    detector = FastDetectGPT(args)\n",
        "    print(\"Detector initialized.\")\n",
        "\n",
        "    # 2. Estimate the probability using text from the command line\n",
        "    print(f\"\\nAnalyzing text: '{args.text.strip()[:100]}...'\")\n",
        "    prob, crit, ntokens = detector.compute_prob(args.text)\n",
        "\n",
        "    # 3. Print the result\n",
        "    print(f'\\n--- Result ---')\n",
        "    if np.isnan(crit):\n",
        "        print(f'Could not analyze text. It might be too short or invalid.')\n",
        "    else:\n",
        "        print(f'Fast-DetectGPT criterion is {crit:.4f}')\n",
        "        print(f'Probability of being machine-generated: {prob * 100:.0f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEZuFEWS_78w",
        "outputId": "d12a07d5-fc07-4e67-901d-4a5b5516c97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/local_infer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run FAST-DETECT-GPT on google colab"
      ],
      "metadata": {
        "id": "kGY4kqX2Ir4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/local_infer.py --sampling_model_name \"gpt-neo-2.7B\" --scoring_model_name \"gpt-neo-2.7B\" --text \"I went to the store this morning to buy some groceries. I wasn't sure what to make for dinner, so I just grabbed some chicken, vegetables, and pasta.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2X9eIJS-IwS",
        "outputId": "b4613376-9c95-4694-b700-5cfea3b3d8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing detector...\n",
            "tokenizer_config.json: 100% 200/200 [00:00<00:00, 1.22MB/s]\n",
            "config.json: 1.46kB [00:00, 7.48MB/s]\n",
            "vocab.json: 798kB [00:00, 87.2MB/s]\n",
            "merges.txt: 456kB [00:00, 113MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 226kB/s]\n",
            "Loading model EleutherAI/gpt-neo-2.7B...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2025-10-20 19:20:34.321626: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-20 19:20:34.338547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760988034.359661    1194 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760988034.366019    1194 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760988034.382216    1194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760988034.382244    1194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760988034.382247    1194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760988034.382250    1194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-20 19:20:34.387180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 10.7G/10.7G [00:57<00:00, 187MB/s]\n",
            "Moving model to GPU...DONE (1.61s)\n",
            "Detector initialized.\n",
            "\n",
            "Analyzing text: 'I went to the store this morning to buy some groceries. I wasn't sure what to make for dinner, so I ...'\n",
            "\n",
            "--- Result ---\n",
            "Fast-DetectGPT criterion is 2.7539\n",
            "Probability of being machine-generated: 98%\n"
          ]
        }
      ]
    }
  ]
}